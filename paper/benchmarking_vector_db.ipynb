{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Base part"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "import abc\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class DotModel(BaseModel):\n",
    "    uid: str\n",
    "    vector: list[float]\n",
    "\n",
    "\n",
    "class VectorClient(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def push_dots(self, dots: list[DotModel]):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def query_dot(self, vector: list[float], limit: int = 15) -> list[DotModel]:\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def create_collection(self):\n",
    "        pass\n",
    "\n",
    "    def start_pushing(self):\n",
    "        self._start_pushing_time = datetime.datetime.now()\n",
    "\n",
    "    def end_pushing(self):\n",
    "        delta = datetime.datetime.now() - self._start_pushing_time\n",
    "        logger.info(f'end pushing {type(self).__name__} in {delta}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-21T14:11:15.432185583Z",
     "start_time": "2025-03-21T14:11:15.339122437Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from create_embeddings.schemas.embedding import ProductEmbedding, ModelEnum\n",
    "from parsers.runnures.utils.csv import CsvReader\n",
    "\n",
    "from create_embeddings.schemas.embedding_model import EmbeddingModelCsvFile, embedding_size_map\n",
    "from create_embeddings.utils import get_csv_files_info\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "USED_MODEL = ModelEnum.MULTILINGUAL_E5_LARGE_INSTRUCT\n",
    "VECTOR_LEN = embedding_size_map[USED_MODEL]\n",
    "\n",
    "\n",
    "def populate_embeddings(client: VectorClient):\n",
    "    csv_files_info: list[EmbeddingModelCsvFile] = get_csv_files_info()\n",
    "\n",
    "    client.create_collection()\n",
    "    logger.info(f'collection created {type(client).__name__}')\n",
    "\n",
    "    i = 0\n",
    "    client.start_pushing()\n",
    "    for csv_file_info in csv_files_info:\n",
    "        if csv_file_info.embedding_model_name != USED_MODEL or \"OBI\" not in csv_file_info.file_path:\n",
    "            continue\n",
    "\n",
    "        logger.info(f'start new file {csv_file_info.file_path.split(\"/\")[-1]}')\n",
    "\n",
    "        batch: list[DotModel] = []\n",
    "        csv_reader: CsvReader[ProductEmbedding] = CsvReader(csv_file_info.file_path, ProductEmbedding)\n",
    "        for uid_vector in csv_reader:\n",
    "            i += 1\n",
    "            batch.append(DotModel(id=uid_vector.uid, vector=uid_vector.embedding))\n",
    "            if len(batch) == BATCH_SIZE:\n",
    "                logger.info(f'uploading {i} points to {type(client).__name__}')\n",
    "                client.push_dots(batch)\n",
    "                batch = []\n",
    "\n",
    "        client.push_dots(batch)\n",
    "        batch = []\n",
    "    client.end_pushing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "import time\n",
    "\n",
    "TEST_DURATION = 60\n",
    "\n",
    "\n",
    "def call_get_dot_with_rps(client: VectorClient, rps: int):\n",
    "    now = time.time()\n",
    "    end_time = now + TEST_DURATION\n",
    "    sleep_interval = 1 / rps\n",
    "    next_call = now + sleep_interval\n",
    "    point_generator = next_point()\n",
    "\n",
    "    while now < end_time:\n",
    "        now = time.time()\n",
    "        if now >= next_call:\n",
    "            client.get_dot(next(point_generator))\n",
    "            next_call = next_call + sleep_interval\n",
    "\n",
    "\n",
    "def call_get_dot_with_max_single_core_rps(client: VectorClient):\n",
    "    now = time.time()\n",
    "    end_time = now + TEST_DURATION\n",
    "    point_generator = next_point()\n",
    "\n",
    "    while now < end_time:\n",
    "        now = time.time()\n",
    "        client.get_dot(next(point_generator))\n",
    "\n",
    "\n",
    "def next_point(include_random=True) -> Generator[None, list[float], None]:\n",
    "    csv_files_info: list[EmbeddingModelCsvFile] = get_csv_files_info()\n",
    "    while True:\n",
    "        for csv_file_info in csv_files_info:\n",
    "            if csv_file_info.embedding_model_name != USED_MODEL or \"STROYDVOR\" not in csv_file_info.file_path:\n",
    "                continue\n",
    "\n",
    "            csv_reader: CsvReader[ProductEmbedding] = CsvReader(csv_file_info.file_path, ProductEmbedding)\n",
    "            for uid_vector in csv_reader:\n",
    "                if include_random:\n",
    "                    while True:\n",
    "                        use_random = random.randint(0, 1)\n",
    "                        if use_random:\n",
    "                            yield get_random_point(VECTOR_LEN)\n",
    "                        else:\n",
    "                            yield uid_vector.embedding\n",
    "                else:\n",
    "                    yield uid_vector.embedding\n",
    "\n",
    "\n",
    "def get_random_point(l: int) -> list[float]:\n",
    "    return [random.random() for _ in range(l)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Clients"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Qdarant\n",
    "\n",
    "```\n",
    "docker run -d -p 8900:6333 \\\n",
    "    -v ~volumes/benchmark_vector_db/qdrant:/qdrant/storage \\\n",
    "    qdrant/qdrant\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from qdrant_client.http import models as qdrant_models\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "\n",
    "class QdrantVectorClient(VectorClient):\n",
    "    def __init__(self):\n",
    "        QDRANT_CONNECTION_STRING = \"http://localhost:8900\"\n",
    "        self.client = QdrantClient(url=QDRANT_CONNECTION_STRING)\n",
    "        self.collection_name = \"benchmarking_vector_db\"\n",
    "\n",
    "    def push_dots(self, dots: list[DotModel]):\n",
    "        batch = []\n",
    "        for dot in dots:\n",
    "            batch.append(qdrant_models.PointStruct(\n",
    "                id=dot.uid,\n",
    "                vector=dot.vector,\n",
    "            ))\n",
    "        self.client.upload_points(\n",
    "            collection_name=self.collection_name,\n",
    "            points=batch,\n",
    "        )\n",
    "\n",
    "    def query_dot(self, vector: list[float], limit: int = 15) -> list[DotModel]:\n",
    "        hits: list[qdrant_models.ScoredPoint] = self.client.query_points(\n",
    "            collection_name=self.collection_name,\n",
    "            query=vector,\n",
    "            limit=limit,\n",
    "        ).points\n",
    "\n",
    "        result: list[DotModel] = []\n",
    "        for hit in hits:\n",
    "            result.append(DotModel(uid=hit.id, vector=hit.vector))\n",
    "        return result\n",
    "\n",
    "    def create_collection(self):\n",
    "        self.client.create_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            vectors_config=qdrant_models.VectorParams(\n",
    "                size=VECTOR_LEN, distance=qdrant_models.Distance.COSINE, on_disk=True\n",
    "            ),\n",
    "            hnsw_config=qdrant_models.HnswConfigDiff(m=16, ef_construct=128, on_disk=True),\n",
    "            optimizers_config=qdrant_models.OptimizersConfigDiff(indexing_threshold=0),\n",
    "        )\n",
    "\n",
    "    def end_pushing(self):\n",
    "        self.client.update_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            optimizer_config=qdrant_models.OptimizersConfigDiff(indexing_threshold=10_000),\n",
    "        )\n",
    "\n",
    "    super().end_pushing()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Chroma\n",
    "\n",
    "```\n",
    "docker run -d --rm --name chromadb -p 8901:8000 -v ~volumes/benchmark_vector_db/chroma:/chroma/chroma -e IS_PERSISTENT=TRUE chromadb/chroma:0.6.3\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from chromadb.api.types import convert_np_embeddings_to_list\n",
    "import chromadb\n",
    "\n",
    "\n",
    "class ChromaVectorClient(VectorClient):\n",
    "    def __init__(self):\n",
    "        self.client = chromadb.HttpClient(port=8901)\n",
    "        self.collection_name = \"benchmarking_vector_db\"\n",
    "        self.collection: chromadb.Collection = None\n",
    "\n",
    "    def push_dots(self, dots: list[DotModel]):\n",
    "        ids = []\n",
    "        embeddings = []\n",
    "        for dot in dots:\n",
    "            ids.append(dot.uid)\n",
    "            embeddings.append(dot.vector)\n",
    "\n",
    "        self.collection.add(\n",
    "            ids=ids,\n",
    "            embeddings=embeddings,\n",
    "        )\n",
    "\n",
    "    def query_dot(self, vector: list[float], limit: int = 15) -> list[DotModel]:\n",
    "        result: chromadb.QueryResult = self.collection.query(\n",
    "            query_embeddings=vector,\n",
    "            n_results=limit,\n",
    "        )\n",
    "\n",
    "        result: list[DotModel] = []\n",
    "        for i in range(len(result[\"ids\"])):\n",
    "            embeddings = result[\"embeddings\"][i]\n",
    "            if isinstance(embeddings, chromadb.Embeddings):\n",
    "                embeddings = convert_np_embeddings_to_list(embeddings)\n",
    "            result.append(DotModel(uid=result[\"ids\"][i], vector=embeddings))\n",
    "        return result\n",
    "\n",
    "    def create_collection(self):\n",
    "        self.collection = self.client.create_collection(\n",
    "            self.collection_name,\n",
    "            metadata={\n",
    "                \"hnsw:space\": \"cosine\",\n",
    "                \"hnsw:construction_ef\": 128,\n",
    "                \"hnsw:M\": 16,\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Elasticsearch\n",
    "\n",
    "```\n",
    "docker run --name elastic -p 8902:9200 -d -m 1GB -e ELASTIC_PASSWORD=password docker.elastic.co/elasticsearch/elasticsearch:8.17.3\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from elasticsearch.helpers import bulk\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "class ElasticVectorClient(VectorClient):\n",
    "    def __init__(self):\n",
    "        self.client = Elasticsearch(\n",
    "            \"https://localhost:8902\",\n",
    "            basic_auth=(\"elastic\", \"password\"),\n",
    "            verify_certs=False,\n",
    "        )\n",
    "        self.collection_name = \"benchmarking_vector_db\" \n",
    "    \n",
    "    def push_dots(self, dots: list[DotModel]):\n",
    "        actions = [\n",
    "            {\n",
    "                \"_op_type\": \"index\",\n",
    "                \"_index\": self.collection_name,\n",
    "                \"_id\": dot.uid,\n",
    "                \"_source\": {\n",
    "                    \"embedding\": dot.vector\n",
    "                }\n",
    "            }\n",
    "            for dot in dots\n",
    "        ]\n",
    "        bulk(self.client, actions)\n",
    "\n",
    "    def query_dot(self, vector: list[float], limit: int = 15) -> list[DotModel]:\n",
    "        query = {\n",
    "            \"size\": limit,\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"embedding\": {\n",
    "                        \"vector\": vector,\n",
    "                        \"k\": limit\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = self.client.search(index=self.collection_name, body=query)\n",
    "        results = []\n",
    "        for hit in response['hits']['hits']:\n",
    "            uid = hit['_id']\n",
    "            embedding = hit['_source']['embedding']\n",
    "            results.append(DotModel(uid=uid, vector=embedding))\n",
    "        return results\n",
    "\n",
    "    def create_collection(self):\n",
    "        self.client.indices.create(\n",
    "            index=\"my_index\",\n",
    "            mappings={\n",
    "                \"properties\": {\n",
    "                    \"embedding\": {\n",
    "                        \"type\": \"dense_vector\",\n",
    "                        \"dims\": VECTOR_LEN,\n",
    "                        \"index\": \"true\",\n",
    "                        \"similarity\": \"cosine\",\n",
    "                        \"element_type\": \"float\",\n",
    "                        \"index_options\": {\n",
    "                            \"type\": \"hnsw\",\n",
    "                            \"ef_construction\": 128,\n",
    "                            \"m\": 16,\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Postgres\n",
    "\n",
    "```\n",
    "docker run --name pgvector -d -p 8903:5432 -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=password -e POSTGRES_DB=benchmarking_vector_db -v ~volumes/benchmark_vector_db/pgvector:/var/lib/postgresql/data pgvector/pgvector:pg17\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from uuid import uuid4\n",
    "from sqlalchemy import create_engine, text\n",
    "from elasticsearch.helpers import bulk\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "class PgvectorVectorClient(VectorClient):\n",
    "    def __init__(self):\n",
    "        self.engine = create_engine(\"postgresql+psycopg2://postgres:password@localhost:8903/benchmarking_vector_db\")\n",
    "        self.collection_name = \"benchmarking_vector_db\" \n",
    "    \n",
    "    def push_dots(self, dots: list[DotModel]):\n",
    "        actions = [\n",
    "            {\n",
    "                \"_op_type\": \"index\",\n",
    "                \"_index\": self.collection_name,\n",
    "                \"_id\": dot.uid,\n",
    "                \"_source\": {\n",
    "                    \"embedding\": dot.vector\n",
    "                }\n",
    "            }\n",
    "            for dot in dots\n",
    "        ]\n",
    "        bulk(self.client, actions)\n",
    "\n",
    "    def query_dot(self, vector: list[float], limit: int = 15) -> list[DotModel]:\n",
    "        query = {\n",
    "            \"size\": limit,\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"embedding\": {\n",
    "                        \"vector\": vector,\n",
    "                        \"k\": limit\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = self.client.search(index=self.collection_name, body=query)\n",
    "        results = []\n",
    "        for hit in response['hits']['hits']:\n",
    "            uid = hit['_id']\n",
    "            embedding = hit['_source']['embedding']\n",
    "            results.append(DotModel(uid=uid, vector=embedding))\n",
    "        return results\n",
    "\n",
    "    def create_collection(self):\n",
    "        with self.engine.connect() as connection:\n",
    "            result = connection.execute(\n",
    "                text(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "            )\n",
    "            \n",
    "            result = connection.execute(\n",
    "                text(\"\"\"\n",
    "                CREATE TABLE items (\n",
    "                    uid ??? PRIMARY KEY,\n",
    "                    embedding vector(:vector_len) -- vector data\n",
    "                );\n",
    "                \"\"\",\n",
    "                     {\"uuid_len\": len(str(uuid4())), \"vector_len\": VECTOR_LEN})\n",
    "            )\n",
    "        # self.client.indices.create(\n",
    "        #     index=\"my_index\",\n",
    "        #     mappings={\n",
    "        #         \"properties\": {\n",
    "        #             \"embedding\": {\n",
    "        #                 \"type\": \"dense_vector\",\n",
    "        #                 \"dims\": VECTOR_LEN,\n",
    "        #                 \"index\": \"true\",\n",
    "        #                 \"similarity\": \"cosine\",\n",
    "        #                 \"element_type\": \"float\",\n",
    "        #                 \"index_options\": {\n",
    "        #                     \"type\": \"hnsw\",\n",
    "        #                     \"ef_construction\": 128,\n",
    "        #                     \"m\": 16,\n",
    "        #                 }\n",
    "        #             }\n",
    "        #         }\n",
    "        #     }\n",
    "        # )\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run Tests"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
