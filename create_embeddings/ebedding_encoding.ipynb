{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jo-LuGqBg9N4",
    "outputId": "c565cd7d-2ed3-4e34-9ab9-5e2b9d9517b3",
    "ExecuteTime": {
     "end_time": "2024-10-21T20:47:15.112418930Z",
     "start_time": "2024-10-21T20:47:15.109101426Z"
    }
   },
   "outputs": [],
   "source": [
    "from core.logging import service_log, add_file_log\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = str(multiprocessing.cpu_count() - 2)\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = str(multiprocessing.cpu_count())\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "service_log()\n",
    "add_file_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJ7fvzkBjMVa"
   },
   "source": [
    "# Считаем embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bLMO51l1oL0K",
    "ExecuteTime": {
     "end_time": "2024-10-21T20:47:17.217690818Z",
     "start_time": "2024-10-21T20:47:17.118979627Z"
    }
   },
   "outputs": [],
   "source": [
    "from create_embeddings.schemas.embedding import ModelEnum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class EbeddingModel(BaseModel):\n",
    "  name: ModelEnum\n",
    "  param_millions: int\n",
    "  ebedding_size: int\n",
    "  max_tokens: int\n",
    "  rank: int\n",
    "  title_batch_per_gb: int = 250\n",
    "  description_batch_per_gb: int = 250\n",
    "\n",
    "PARAMS_TO_MEMORY_GB_COFICIENT: float = 0.0037572219181414585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dqKgImmAjRZc",
    "ExecuteTime": {
     "end_time": "2024-10-21T20:47:18.650955895Z",
     "start_time": "2024-10-21T20:47:18.646643915Z"
    }
   },
   "outputs": [],
   "source": [
    "ebeddins_list = (\n",
    "    EbeddingModel(name=ModelEnum.RUBERT_TINY_TURBO, param_millions=29, ebedding_size=312, max_tokens=2048, rank=12),\n",
    "    EbeddingModel(name=ModelEnum.RUBERT_TINY2, param_millions=29, ebedding_size=312, max_tokens=514, rank=16),\n",
    "    EbeddingModel(name=ModelEnum.LABSE_RU_TURBO, param_millions=128, ebedding_size=768, max_tokens=512, rank=8),\n",
    "    EbeddingModel(name=ModelEnum.MULTILINGUAL_E5_LARGE_INSTRUCT, param_millions=560, ebedding_size=1024, max_tokens=514, rank=2),\n",
    "    EbeddingModel(name=ModelEnum.BGE_M3, param_millions=567, ebedding_size=1024,\tmax_tokens=8192, rank=5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JTh7ohT8tRde",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fb60d20f-b8dc-4a6f-cac5-1d93d30c209a",
    "ExecuteTime": {
     "end_time": "2024-10-21T20:47:21.212857806Z",
     "start_time": "2024-10-21T20:47:20.005706554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from parsers.runnures.schemas.product import StoreEnum\n",
    "from create_embeddings.schemas.embedding import EmbeddingsFieldsEnum\n",
    "\n",
    "store_map = {\n",
    "    StoreEnum.STROYDVOR: '/home/roman/PycharmProjects/personal/diploma/parsers/runnures/stroydvor/data/products.csv',\n",
    "    StoreEnum.OBI: '/home/roman/PycharmProjects/personal/diploma/parsers/runnures/obi/data/products_merged.csv',\n",
    "}\n",
    "uid_column = 'uid'\n",
    "fields_to_encode = [EmbeddingsFieldsEnum.TITLE, EmbeddingsFieldsEnum.DESCRIPTION]\n",
    "# BATCH_SIZE = 1000\n",
    "BATCH_SIZE = 200\n",
    "# fields_to_encode = ['title', 'description', 'properties__as_text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T20:47:22.427918348Z",
     "start_time": "2024-10-21T20:47:22.422547355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "start_from_model = ModelEnum.MULTILINGUAL_E5_LARGE_INSTRUCT\n",
    "start_from_store = StoreEnum.OBI\n",
    "start_from_field = EmbeddingsFieldsEnum.DESCRIPTION"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T20:47:25.178185014Z",
     "start_time": "2024-10-21T20:47:25.173538330Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 23:47:29,124 - numexpr.utils - INFO - Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-10-21 23:47:29,257 - __main__ - INFO - ebedding: intfloat/multilingual-e5-large-instruct\n",
      "2024-10-21 23:47:31,657 - __main__ - INFO - store: OBI\n",
      "/tmp/ipykernel_2424/3291779062.py:22: DtypeWarning: Columns (35,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "2024-10-21 23:47:33,518 - __main__ - INFO - field: description\n",
      "2024-10-21 23:51:07,783 - __main__ - INFO - written batch 0 | runtime torch.Size([197, 512]): 0:03:34.263835\n",
      "2024-10-21 23:54:41,356 - __main__ - INFO - written batch 1 | runtime torch.Size([195, 512]): 0:03:33.572465\n",
      "2024-10-21 23:58:14,197 - __main__ - INFO - written batch 2 | runtime torch.Size([197, 503]): 0:03:32.840162\n",
      "2024-10-22 00:01:46,390 - __main__ - INFO - written batch 3 | runtime torch.Size([193, 512]): 0:03:32.191817\n",
      "2024-10-22 00:04:50,128 - __main__ - INFO - written batch 4 | runtime torch.Size([190, 457]): 0:03:03.737325\n",
      "2024-10-22 00:07:17,636 - __main__ - INFO - written batch 5 | runtime torch.Size([194, 374]): 0:02:27.508085\n",
      "2024-10-22 00:10:49,369 - __main__ - INFO - written batch 6 | runtime torch.Size([190, 512]): 0:03:31.731813\n",
      "2024-10-22 00:14:12,842 - __main__ - INFO - written batch 7 | runtime torch.Size([184, 512]): 0:03:23.472518\n",
      "2024-10-22 00:17:44,513 - __main__ - INFO - written batch 8 | runtime torch.Size([191, 512]): 0:03:31.670168\n",
      "2024-10-22 00:21:13,666 - __main__ - INFO - written batch 9 | runtime torch.Size([188, 512]): 0:03:29.151983\n",
      "2024-10-22 00:24:43,000 - __main__ - INFO - written batch 10 | runtime torch.Size([189, 512]): 0:03:29.333294\n",
      "2024-10-22 00:28:18,296 - __main__ - INFO - written batch 11 | runtime torch.Size([195, 512]): 0:03:35.295014\n",
      "2024-10-22 00:30:54,388 - __main__ - INFO - written batch 12 | runtime torch.Size([197, 392]): 0:02:36.091973\n",
      "2024-10-22 00:34:29,156 - __main__ - INFO - written batch 13 | runtime torch.Size([194, 512]): 0:03:34.767704\n",
      "2024-10-22 00:37:32,955 - __main__ - INFO - written batch 14 | runtime torch.Size([191, 455]): 0:03:03.797604\n",
      "2024-10-22 00:41:03,662 - __main__ - INFO - written batch 15 | runtime torch.Size([191, 512]): 0:03:30.706417\n",
      "2024-10-22 00:44:43,828 - __main__ - INFO - written batch 16 | runtime torch.Size([198, 512]): 0:03:40.164687\n",
      "2024-10-22 00:47:12,797 - __main__ - INFO - written batch 17 | runtime torch.Size([191, 381]): 0:02:28.968981\n",
      "2024-10-22 00:49:26,007 - __main__ - INFO - written batch 18 | runtime torch.Size([190, 352]): 0:02:13.208799\n",
      "2024-10-22 00:52:01,904 - __main__ - INFO - written batch 19 | runtime torch.Size([194, 394]): 0:02:35.895529\n",
      "2024-10-22 00:54:28,302 - __main__ - INFO - written batch 20 | runtime torch.Size([190, 379]): 0:02:26.397304\n",
      "2024-10-22 00:57:50,159 - __main__ - INFO - written batch 21 | runtime torch.Size([183, 512]): 0:03:21.856877\n",
      "2024-10-22 01:01:08,248 - __main__ - INFO - written batch 22 | runtime torch.Size([179, 512]): 0:03:18.087926\n",
      "2024-10-22 01:04:22,878 - __main__ - INFO - written batch 23 | runtime torch.Size([176, 512]): 0:03:14.629003\n",
      "2024-10-22 01:07:40,927 - __main__ - INFO - written batch 24 | runtime torch.Size([179, 512]): 0:03:18.048081\n",
      "2024-10-22 01:10:01,451 - __main__ - INFO - written batch 25 | runtime torch.Size([165, 412]): 0:02:20.523281\n",
      "2024-10-22 01:12:58,116 - __main__ - INFO - written batch 26 | runtime torch.Size([159, 512]): 0:02:56.664996\n",
      "2024-10-22 01:15:36,321 - __main__ - INFO - written batch 27 | runtime torch.Size([143, 512]): 0:02:38.203876\n",
      "2024-10-22 01:18:03,286 - __main__ - INFO - written batch 28 | runtime torch.Size([151, 457]): 0:02:26.964439\n",
      "2024-10-22 01:20:33,248 - __main__ - INFO - written batch 29 | runtime torch.Size([154, 457]): 0:02:29.961047\n",
      "2024-10-22 01:22:19,335 - __main__ - INFO - written batch 30 | runtime torch.Size([141, 367]): 0:01:46.086865\n",
      "2024-10-22 01:25:18,520 - __main__ - INFO - written batch 31 | runtime torch.Size([161, 512]): 0:02:59.184126\n",
      "2024-10-22 01:28:50,379 - __main__ - INFO - written batch 32 | runtime torch.Size([191, 512]): 0:03:31.857917\n",
      "2024-10-22 01:32:25,224 - __main__ - INFO - written batch 33 | runtime torch.Size([194, 512]): 0:03:34.844411\n",
      "2024-10-22 01:35:52,229 - __main__ - INFO - written batch 34 | runtime torch.Size([187, 512]): 0:03:27.004694\n",
      "2024-10-22 01:39:16,909 - __main__ - INFO - written batch 35 | runtime torch.Size([185, 512]): 0:03:24.679310\n",
      "2024-10-22 01:42:46,480 - __main__ - INFO - written batch 36 | runtime torch.Size([190, 506]): 0:03:29.569919\n",
      "2024-10-22 01:45:46,175 - __main__ - INFO - written batch 37 | runtime torch.Size([179, 469]): 0:02:59.694844\n",
      "2024-10-22 01:48:54,420 - __main__ - INFO - written batch 38 | runtime torch.Size([188, 467]): 0:03:08.243769\n",
      "2024-10-22 01:52:22,980 - __main__ - INFO - written batch 39 | runtime torch.Size([188, 512]): 0:03:28.559189\n",
      "2024-10-22 01:54:35,218 - __main__ - INFO - written batch 40 | runtime torch.Size([191, 345]): 0:02:12.238199\n",
      "2024-10-22 01:58:00,153 - __main__ - INFO - written batch 41 | runtime torch.Size([185, 512]): 0:03:24.933272\n",
      "2024-10-22 02:00:24,701 - __main__ - INFO - written batch 42 | runtime torch.Size([182, 386]): 0:02:24.547406\n",
      "2024-10-22 02:02:28,967 - __main__ - INFO - written batch 43 | runtime torch.Size([167, 365]): 0:02:04.265383\n",
      "2024-10-22 02:04:55,269 - __main__ - INFO - written batch 44 | runtime torch.Size([167, 419]): 0:02:26.301649\n",
      "2024-10-22 02:07:31,413 - __main__ - INFO - written batch 45 | runtime torch.Size([167, 444]): 0:02:36.143745\n",
      "2024-10-22 02:09:40,773 - __main__ - INFO - written batch 46 | runtime torch.Size([159, 393]): 0:02:09.358532\n",
      "2024-10-22 02:11:19,897 - __main__ - INFO - written batch 47 | runtime torch.Size([155, 319]): 0:01:39.123822\n",
      "2024-10-22 02:14:25,808 - __main__ - INFO - written batch 48 | runtime torch.Size([167, 512]): 0:03:05.909497\n",
      "2024-10-22 02:17:41,515 - __main__ - INFO - written batch 49 | runtime torch.Size([176, 512]): 0:03:15.706511\n",
      "2024-10-22 02:21:01,785 - __main__ - INFO - written batch 50 | runtime torch.Size([180, 512]): 0:03:20.269387\n",
      "2024-10-22 02:24:29,736 - __main__ - INFO - written batch 51 | runtime torch.Size([187, 512]): 0:03:27.949899\n",
      "2024-10-22 02:28:08,011 - __main__ - INFO - written batch 52 | runtime torch.Size([196, 512]): 0:03:38.274569\n",
      "2024-10-22 02:31:40,355 - __main__ - INFO - written batch 53 | runtime torch.Size([191, 512]): 0:03:32.343508\n",
      "2024-10-22 02:35:12,201 - __main__ - INFO - written batch 54 | runtime torch.Size([191, 512]): 0:03:31.845343\n",
      "2024-10-22 02:38:45,122 - __main__ - INFO - written batch 55 | runtime torch.Size([192, 512]): 0:03:32.920510\n",
      "2024-10-22 02:42:07,169 - __main__ - INFO - written batch 56 | runtime torch.Size([183, 506]): 0:03:22.045744\n",
      "2024-10-22 02:44:48,586 - __main__ - INFO - written batch 57 | runtime torch.Size([180, 427]): 0:02:41.416044\n",
      "2024-10-22 02:46:55,292 - __main__ - INFO - written batch 58 | runtime torch.Size([179, 349]): 0:02:06.705711\n",
      "2024-10-22 02:48:55,421 - __main__ - INFO - written batch 59 | runtime torch.Size([173, 343]): 0:02:00.128010\n",
      "2024-10-22 02:50:57,349 - __main__ - INFO - written batch 60 | runtime torch.Size([172, 352]): 0:02:01.927589\n",
      "2024-10-22 02:53:18,774 - __main__ - INFO - written batch 61 | runtime torch.Size([170, 402]): 0:02:21.424066\n",
      "2024-10-22 02:55:09,811 - __main__ - INFO - written batch 62 | runtime torch.Size([175, 320]): 0:01:51.035254\n",
      "2024-10-22 02:57:49,682 - __main__ - INFO - written batch 63 | runtime torch.Size([188, 410]): 0:02:39.870510\n",
      "2024-10-22 03:00:21,775 - __main__ - INFO - written batch 64 | runtime torch.Size([183, 402]): 0:02:32.092156\n",
      "2024-10-22 03:02:47,513 - __main__ - INFO - written batch 65 | runtime torch.Size([183, 387]): 0:02:25.737561\n",
      "2024-10-22 03:04:45,381 - __main__ - INFO - written batch 66 | runtime torch.Size([186, 320]): 0:01:57.866533\n",
      "2024-10-22 03:06:46,655 - __main__ - INFO - written batch 67 | runtime torch.Size([191, 320]): 0:02:01.273651\n",
      "2024-10-22 03:08:42,830 - __main__ - INFO - written batch 68 | runtime torch.Size([183, 320]): 0:01:56.174487\n",
      "2024-10-22 03:11:21,826 - __main__ - INFO - written batch 69 | runtime torch.Size([187, 410]): 0:02:38.995605\n",
      "2024-10-22 03:13:59,389 - __main__ - INFO - written batch 70 | runtime torch.Size([185, 410]): 0:02:37.562288\n",
      "2024-10-22 03:15:56,947 - __main__ - INFO - written batch 71 | runtime torch.Size([186, 320]): 0:01:57.557512\n",
      "2024-10-22 03:17:17,276 - __main__ - INFO - written batch 72 | runtime torch.Size([191, 221]): 0:01:20.328056\n",
      "2024-10-22 03:18:45,628 - __main__ - INFO - written batch 73 | runtime torch.Size([185, 248]): 0:01:28.350963\n",
      "2024-10-22 03:20:42,980 - __main__ - INFO - written batch 74 | runtime torch.Size([185, 320]): 0:01:57.351741\n",
      "2024-10-22 03:22:27,418 - __main__ - INFO - written batch 75 | runtime torch.Size([179, 295]): 0:01:44.436979\n",
      "2024-10-22 03:23:54,732 - __main__ - INFO - written batch 76 | runtime torch.Size([174, 259]): 0:01:27.313552\n",
      "2024-10-22 03:25:11,015 - __main__ - INFO - written batch 77 | runtime torch.Size([159, 248]): 0:01:16.281660\n",
      "2024-10-22 03:28:32,714 - __main__ - INFO - written batch 78 | runtime torch.Size([181, 512]): 0:03:21.698831\n",
      "2024-10-22 03:31:59,714 - __main__ - INFO - written batch 79 | runtime torch.Size([186, 512]): 0:03:26.998987\n",
      "2024-10-22 03:35:33,455 - __main__ - INFO - written batch 80 | runtime torch.Size([192, 512]): 0:03:33.740857\n",
      "2024-10-22 03:38:46,734 - __main__ - INFO - written batch 81 | runtime torch.Size([185, 481]): 0:03:13.278051\n",
      "2024-10-22 03:41:23,198 - __main__ - INFO - written batch 82 | runtime torch.Size([174, 427]): 0:02:36.462464\n",
      "2024-10-22 03:44:29,656 - __main__ - INFO - written batch 83 | runtime torch.Size([167, 512]): 0:03:06.457265\n",
      "2024-10-22 03:47:39,301 - __main__ - INFO - written batch 84 | runtime torch.Size([170, 512]): 0:03:09.644329\n",
      "2024-10-22 03:51:12,104 - __main__ - INFO - written batch 85 | runtime torch.Size([191, 512]): 0:03:32.802252\n",
      "2024-10-22 03:54:41,386 - __main__ - INFO - written batch 86 | runtime torch.Size([188, 512]): 0:03:29.281329\n",
      "2024-10-22 03:58:10,193 - __main__ - INFO - written batch 87 | runtime torch.Size([188, 512]): 0:03:28.806874\n",
      "2024-10-22 04:01:42,371 - __main__ - INFO - written batch 88 | runtime torch.Size([191, 512]): 0:03:32.176920\n",
      "2024-10-22 04:05:06,587 - __main__ - INFO - written batch 89 | runtime torch.Size([183, 512]): 0:03:24.215140\n",
      "2024-10-22 04:08:37,516 - __main__ - INFO - written batch 90 | runtime torch.Size([189, 512]): 0:03:30.928894\n",
      "2024-10-22 04:11:55,538 - __main__ - INFO - written batch 91 | runtime torch.Size([178, 512]): 0:03:18.020716\n",
      "2024-10-22 04:15:25,686 - __main__ - INFO - written batch 92 | runtime torch.Size([189, 512]): 0:03:30.147110\n",
      "2024-10-22 04:19:00,399 - __main__ - INFO - written batch 93 | runtime torch.Size([193, 512]): 0:03:34.712596\n",
      "2024-10-22 04:22:27,477 - __main__ - INFO - written batch 94 | runtime torch.Size([186, 512]): 0:03:27.077086\n",
      "2024-10-22 04:25:48,924 - __main__ - INFO - written batch 95 | runtime torch.Size([181, 512]): 0:03:21.446307\n",
      "2024-10-22 04:29:15,016 - __main__ - INFO - written batch 96 | runtime torch.Size([184, 512]): 0:03:26.091188\n",
      "2024-10-22 04:32:36,875 - __main__ - INFO - written batch 97 | runtime torch.Size([181, 512]): 0:03:21.857805\n",
      "2024-10-22 04:36:05,652 - __main__ - INFO - written batch 98 | runtime torch.Size([188, 512]): 0:03:28.776389\n",
      "2024-10-22 04:39:26,174 - __main__ - INFO - written batch 99 | runtime torch.Size([181, 512]): 0:03:20.521948\n",
      "2024-10-22 04:42:14,255 - __main__ - INFO - written batch 100 | runtime torch.Size([176, 450]): 0:02:48.079877\n",
      "2024-10-22 04:45:17,401 - __main__ - INFO - written batch 101 | runtime torch.Size([175, 488]): 0:03:03.145623\n",
      "2024-10-22 04:48:12,548 - __main__ - INFO - written batch 102 | runtime torch.Size([167, 488]): 0:02:55.146357\n",
      "2024-10-22 04:51:32,760 - __main__ - INFO - written batch 103 | runtime torch.Size([179, 512]): 0:03:20.210821\n",
      "2024-10-22 04:54:48,486 - __main__ - INFO - written batch 104 | runtime torch.Size([175, 512]): 0:03:15.725889\n",
      "2024-10-22 04:57:55,913 - __main__ - INFO - written batch 105 | runtime torch.Size([167, 512]): 0:03:07.425860\n",
      "2024-10-22 05:00:32,549 - __main__ - INFO - written batch 106 | runtime torch.Size([167, 442]): 0:02:36.635903\n",
      "2024-10-22 05:03:23,637 - __main__ - INFO - written batch 107 | runtime torch.Size([153, 512]): 0:02:51.087034\n",
      "2024-10-22 05:06:11,556 - __main__ - INFO - written batch 108 | runtime torch.Size([150, 512]): 0:02:47.918023\n",
      "2024-10-22 05:09:08,686 - __main__ - INFO - written batch 109 | runtime torch.Size([159, 512]): 0:02:57.129350\n",
      "2024-10-22 05:11:59,341 - __main__ - INFO - written batch 110 | runtime torch.Size([153, 512]): 0:02:50.654743\n",
      "2024-10-22 05:15:01,624 - __main__ - INFO - written batch 111 | runtime torch.Size([163, 512]): 0:03:02.282153\n",
      "2024-10-22 05:17:57,997 - __main__ - INFO - written batch 112 | runtime torch.Size([158, 512]): 0:02:56.372579\n",
      "2024-10-22 05:20:57,484 - __main__ - INFO - written batch 113 | runtime torch.Size([161, 512]): 0:02:59.485804\n",
      "2024-10-22 05:23:47,711 - __main__ - INFO - written batch 114 | runtime torch.Size([152, 512]): 0:02:50.226887\n",
      "2024-10-22 05:26:34,418 - __main__ - INFO - written batch 115 | runtime torch.Size([165, 470]): 0:02:46.705450\n",
      "2024-10-22 05:29:16,573 - __main__ - INFO - written batch 116 | runtime torch.Size([145, 512]): 0:02:42.155247\n",
      "2024-10-22 05:32:12,398 - __main__ - INFO - written batch 117 | runtime torch.Size([157, 512]): 0:02:55.823928\n",
      "2024-10-22 05:35:02,330 - __main__ - INFO - written batch 118 | runtime torch.Size([151, 510]): 0:02:49.931642\n",
      "2024-10-22 05:37:53,154 - __main__ - INFO - written batch 119 | runtime torch.Size([153, 512]): 0:02:50.822590\n",
      "2024-10-22 05:40:39,208 - __main__ - INFO - written batch 120 | runtime torch.Size([148, 512]): 0:02:46.053973\n",
      "2024-10-22 05:43:23,235 - __main__ - INFO - written batch 121 | runtime torch.Size([146, 512]): 0:02:44.025802\n",
      "2024-10-22 05:46:01,235 - __main__ - INFO - written batch 122 | runtime torch.Size([141, 512]): 0:02:38.000022\n",
      "2024-10-22 05:48:53,013 - __main__ - INFO - written batch 123 | runtime torch.Size([154, 512]): 0:02:51.776484\n",
      "2024-10-22 05:51:35,816 - __main__ - INFO - written batch 124 | runtime torch.Size([146, 512]): 0:02:42.803213\n",
      "2024-10-22 05:54:22,868 - __main__ - INFO - written batch 125 | runtime torch.Size([150, 512]): 0:02:47.050848\n",
      "2024-10-22 05:56:51,446 - __main__ - INFO - written batch 126 | runtime torch.Size([141, 485]): 0:02:28.577895\n",
      "2024-10-22 05:59:38,516 - __main__ - INFO - written batch 127 | runtime torch.Size([149, 512]): 0:02:47.068893\n",
      "2024-10-22 06:02:04,966 - __main__ - INFO - written batch 128 | runtime torch.Size([151, 453]): 0:02:26.449248\n",
      "2024-10-22 06:04:39,641 - __main__ - INFO - written batch 129 | runtime torch.Size([138, 512]): 0:02:34.673898\n",
      "2024-10-22 06:07:21,269 - __main__ - INFO - written batch 130 | runtime torch.Size([144, 512]): 0:02:41.627264\n",
      "2024-10-22 06:10:42,386 - __main__ - INFO - written batch 131 | runtime torch.Size([190, 487]): 0:03:21.116109\n",
      "2024-10-22 06:14:07,260 - __main__ - INFO - written batch 132 | runtime torch.Size([184, 512]): 0:03:24.873056\n",
      "2024-10-22 06:17:21,518 - __main__ - INFO - written batch 133 | runtime torch.Size([174, 512]): 0:03:14.257674\n",
      "2024-10-22 06:20:24,196 - __main__ - INFO - written batch 134 | runtime torch.Size([163, 512]): 0:03:02.677919\n",
      "2024-10-22 06:23:38,405 - __main__ - INFO - written batch 135 | runtime torch.Size([173, 509]): 0:03:14.207136\n",
      "2024-10-22 06:26:47,992 - __main__ - INFO - written batch 136 | runtime torch.Size([170, 512]): 0:03:09.586641\n",
      "2024-10-22 06:30:08,163 - __main__ - INFO - written batch 137 | runtime torch.Size([180, 512]): 0:03:20.170766\n",
      "2024-10-22 06:32:35,195 - __main__ - INFO - written batch 138 | runtime torch.Size([181, 393]): 0:02:27.031388\n",
      "2024-10-22 06:35:11,287 - __main__ - INFO - written batch 139 | runtime torch.Size([181, 413]): 0:02:36.091165\n",
      "2024-10-22 06:37:23,382 - __main__ - INFO - written batch 140 | runtime torch.Size([179, 362]): 0:02:12.093706\n",
      "2024-10-22 06:40:41,086 - __main__ - INFO - written batch 141 | runtime torch.Size([177, 512]): 0:03:17.703484\n",
      "2024-10-22 06:43:21,502 - __main__ - INFO - written batch 142 | runtime torch.Size([172, 439]): 0:02:40.414616\n",
      "2024-10-22 06:46:06,759 - __main__ - INFO - written batch 143 | runtime torch.Size([180, 436]): 0:02:45.257093\n",
      "2024-10-22 06:48:18,216 - __main__ - INFO - written batch 144 | runtime torch.Size([178, 361]): 0:02:11.455157\n",
      "2024-10-22 06:50:47,778 - __main__ - INFO - written batch 145 | runtime torch.Size([184, 393]): 0:02:29.561743\n",
      "2024-10-22 06:53:42,882 - __main__ - INFO - written batch 146 | runtime torch.Size([188, 439]): 0:02:55.102955\n",
      "2024-10-22 06:56:51,658 - __main__ - INFO - written batch 147 | runtime torch.Size([180, 483]): 0:03:08.775174\n",
      "2024-10-22 06:59:33,562 - __main__ - INFO - written batch 148 | runtime torch.Size([174, 439]): 0:02:41.903289\n",
      "2024-10-22 07:02:15,628 - __main__ - INFO - written batch 149 | runtime torch.Size([181, 425]): 0:02:42.065692\n",
      "2024-10-22 07:04:30,431 - __main__ - INFO - written batch 150 | runtime torch.Size([184, 359]): 0:02:14.801842\n",
      "2024-10-22 07:07:25,114 - __main__ - INFO - written batch 151 | runtime torch.Size([185, 448]): 0:02:54.682059\n",
      "2024-10-22 07:09:36,781 - __main__ - INFO - written batch 152 | runtime torch.Size([180, 359]): 0:02:11.667182\n",
      "2024-10-22 07:12:09,512 - __main__ - INFO - written batch 153 | runtime torch.Size([178, 416]): 0:02:32.730222\n",
      "2024-10-22 07:15:01,789 - __main__ - INFO - written batch 154 | runtime torch.Size([179, 456]): 0:02:52.275759\n",
      "2024-10-22 07:17:50,974 - __main__ - INFO - written batch 155 | runtime torch.Size([175, 454]): 0:02:49.183965\n",
      "2024-10-22 07:20:50,303 - __main__ - INFO - written batch 156 | runtime torch.Size([186, 451]): 0:02:59.328829\n",
      "2024-10-22 07:23:11,342 - __main__ - INFO - written batch 157 | runtime torch.Size([177, 385]): 0:02:21.038883\n",
      "2024-10-22 07:25:30,347 - __main__ - INFO - written batch 158 | runtime torch.Size([174, 385]): 0:02:19.003531\n",
      "2024-10-22 07:28:04,832 - __main__ - INFO - written batch 159 | runtime torch.Size([176, 418]): 0:02:34.483980\n",
      "2024-10-22 07:30:34,900 - __main__ - INFO - written batch 160 | runtime torch.Size([173, 414]): 0:02:30.067961\n",
      "2024-10-22 07:33:47,423 - __main__ - INFO - written batch 161 | runtime torch.Size([172, 512]): 0:03:12.521890\n",
      "2024-10-22 07:36:13,483 - __main__ - INFO - written batch 162 | runtime torch.Size([165, 422]): 0:02:26.059832\n",
      "2024-10-22 07:38:16,086 - __main__ - INFO - written batch 163 | runtime torch.Size([154, 385]): 0:02:02.601801\n",
      "2024-10-22 07:40:16,637 - __main__ - INFO - written batch 164 | runtime torch.Size([152, 383]): 0:02:00.550667\n",
      "2024-10-22 07:43:37,167 - __main__ - INFO - written batch 165 | runtime torch.Size([180, 512]): 0:03:20.529552\n",
      "2024-10-22 07:47:02,482 - __main__ - INFO - written batch 166 | runtime torch.Size([184, 512]): 0:03:25.313766\n",
      "2024-10-22 07:50:29,002 - __main__ - INFO - written batch 167 | runtime torch.Size([184, 512]): 0:03:26.519714\n",
      "2024-10-22 07:53:45,301 - __main__ - INFO - written batch 168 | runtime torch.Size([175, 512]): 0:03:16.298249\n",
      "2024-10-22 07:56:51,514 - __main__ - INFO - written batch 169 | runtime torch.Size([186, 465]): 0:03:06.212466\n",
      "2024-10-22 07:59:15,317 - __main__ - INFO - written batch 170 | runtime torch.Size([174, 397]): 0:02:23.801588\n",
      "2024-10-22 08:01:15,781 - __main__ - INFO - written batch 171 | runtime torch.Size([179, 336]): 0:02:00.463706\n",
      "2024-10-22 08:03:35,531 - __main__ - INFO - written batch 172 | runtime torch.Size([178, 384]): 0:02:19.749117\n",
      "2024-10-22 08:05:51,773 - __main__ - INFO - written batch 173 | runtime torch.Size([181, 367]): 0:02:16.241237\n",
      "2024-10-22 08:07:27,656 - __main__ - INFO - written batch 174 | runtime torch.Size([142, 336]): 0:01:35.881914\n",
      "2024-10-22 08:10:15,881 - __main__ - INFO - written batch 175 | runtime torch.Size([186, 430]): 0:02:48.224688\n",
      "2024-10-22 08:12:44,093 - __main__ - INFO - written batch 176 | runtime torch.Size([189, 381]): 0:02:28.211515\n",
      "2024-10-22 08:15:49,126 - __main__ - INFO - written batch 177 | runtime torch.Size([192, 451]): 0:03:05.032073\n",
      "2024-10-22 08:18:34,188 - __main__ - INFO - written batch 178 | runtime torch.Size([182, 429]): 0:02:45.061304\n",
      "2024-10-22 08:20:44,466 - __main__ - INFO - written batch 179 | runtime torch.Size([178, 357]): 0:02:10.278093\n",
      "2024-10-22 08:22:40,468 - __main__ - INFO - written batch 180 | runtime torch.Size([174, 331]): 0:01:56.000806\n",
      "2024-10-22 08:25:12,733 - __main__ - INFO - written batch 181 | runtime torch.Size([169, 427]): 0:02:32.263755\n",
      "2024-10-22 08:27:38,043 - __main__ - INFO - written batch 182 | runtime torch.Size([161, 427]): 0:02:25.309449\n",
      "2024-10-22 08:30:03,136 - __main__ - INFO - written batch 183 | runtime torch.Size([161, 427]): 0:02:25.092212\n",
      "2024-10-22 08:32:15,535 - __main__ - INFO - written batch 184 | runtime torch.Size([166, 385]): 0:02:12.398685\n",
      "2024-10-22 08:34:23,391 - __main__ - INFO - written batch 185 | runtime torch.Size([164, 377]): 0:02:07.855169\n",
      "2024-10-22 08:36:28,979 - __main__ - INFO - written batch 186 | runtime torch.Size([165, 372]): 0:02:05.587670\n",
      "2024-10-22 08:39:27,695 - __main__ - INFO - written batch 187 | runtime torch.Size([167, 492]): 0:02:58.715024\n",
      "2024-10-22 08:41:35,950 - __main__ - INFO - written batch 188 | runtime torch.Size([157, 393]): 0:02:08.254107\n",
      "2024-10-22 08:43:49,472 - __main__ - INFO - written batch 189 | runtime torch.Size([165, 391]): 0:02:13.520930\n",
      "2024-10-22 08:46:01,983 - __main__ - INFO - written batch 190 | runtime torch.Size([165, 392]): 0:02:12.510121\n",
      "2024-10-22 08:48:06,129 - __main__ - INFO - written batch 191 | runtime torch.Size([164, 369]): 0:02:04.145538\n",
      "2024-10-22 08:49:57,081 - __main__ - INFO - written batch 192 | runtime torch.Size([143, 375]): 0:01:50.951673\n",
      "2024-10-22 08:51:55,239 - __main__ - INFO - written batch 193 | runtime torch.Size([156, 369]): 0:01:58.156909\n",
      "2024-10-22 08:54:01,169 - __main__ - INFO - written batch 194 | runtime torch.Size([146, 412]): 0:02:05.928966\n",
      "2024-10-22 08:55:44,712 - __main__ - INFO - written batch 195 | runtime torch.Size([136, 369]): 0:01:43.542128\n",
      "2024-10-22 08:57:32,428 - __main__ - INFO - written batch 196 | runtime torch.Size([139, 373]): 0:01:47.716210\n",
      "2024-10-22 08:58:57,808 - __main__ - INFO - written batch 197 | runtime torch.Size([130, 323]): 0:01:25.378561\n",
      "2024-10-22 09:00:50,928 - __main__ - INFO - written batch 198 | runtime torch.Size([126, 422]): 0:01:53.119096\n",
      "2024-10-22 09:02:46,145 - __main__ - INFO - written batch 199 | runtime torch.Size([133, 412]): 0:01:55.216868\n",
      "2024-10-22 09:04:15,683 - __main__ - INFO - written batch 200 | runtime torch.Size([117, 369]): 0:01:29.537146\n",
      "2024-10-22 09:05:41,537 - __main__ - INFO - written batch 201 | runtime torch.Size([127, 333]): 0:01:25.853123\n",
      "2024-10-22 09:07:26,656 - __main__ - INFO - written batch 202 | runtime torch.Size([121, 412]): 0:01:45.117648\n",
      "2024-10-22 09:09:11,339 - __main__ - INFO - written batch 203 | runtime torch.Size([126, 400]): 0:01:44.682783\n",
      "2024-10-22 09:12:33,699 - __main__ - INFO - written batch 204 | runtime torch.Size([181, 512]): 0:03:22.359309\n",
      "2024-10-22 09:16:14,764 - __main__ - INFO - written batch 205 | runtime torch.Size([197, 512]): 0:03:41.064053\n",
      "2024-10-22 09:19:40,391 - __main__ - INFO - written batch 206 | runtime torch.Size([183, 512]): 0:03:25.626526\n",
      "2024-10-22 09:22:57,839 - __main__ - INFO - written batch 207 | runtime torch.Size([177, 506]): 0:03:17.446890\n",
      "2024-10-22 09:26:03,616 - __main__ - INFO - written batch 208 | runtime torch.Size([165, 512]): 0:03:05.776147\n",
      "2024-10-22 09:29:01,746 - __main__ - INFO - written batch 209 | runtime torch.Size([164, 494]): 0:02:58.129918\n",
      "2024-10-22 09:32:15,773 - __main__ - INFO - written batch 210 | runtime torch.Size([173, 512]): 0:03:14.026265\n",
      "2024-10-22 09:34:44,880 - __main__ - INFO - written batch 211 | runtime torch.Size([161, 434]): 0:02:29.106056\n",
      "2024-10-22 09:37:06,509 - __main__ - INFO - written batch 212 | runtime torch.Size([162, 415]): 0:02:21.628108\n",
      "2024-10-22 09:40:24,671 - __main__ - INFO - written batch 213 | runtime torch.Size([177, 512]): 0:03:18.161616\n",
      "2024-10-22 09:42:52,536 - __main__ - INFO - written batch 214 | runtime torch.Size([170, 414]): 0:02:27.864265\n",
      "2024-10-22 09:45:55,271 - __main__ - INFO - written batch 215 | runtime torch.Size([188, 453]): 0:03:02.734136\n",
      "2024-10-22 09:48:20,835 - __main__ - INFO - written batch 216 | runtime torch.Size([184, 384]): 0:02:25.563051\n",
      "2024-10-22 09:51:29,123 - __main__ - INFO - written batch 217 | runtime torch.Size([179, 482]): 0:03:08.287046\n",
      "2024-10-22 09:54:45,363 - __main__ - INFO - written batch 218 | runtime torch.Size([175, 512]): 0:03:16.239986\n",
      "2024-10-22 09:57:27,743 - __main__ - INFO - written batch 219 | runtime torch.Size([191, 407]): 0:02:42.378660\n",
      "2024-10-22 09:59:52,835 - __main__ - INFO - written batch 220 | runtime torch.Size([184, 384]): 0:02:25.091398\n",
      "2024-10-22 10:02:12,165 - __main__ - INFO - written batch 221 | runtime torch.Size([188, 361]): 0:02:19.329674\n",
      "2024-10-22 10:04:18,050 - __main__ - INFO - written batch 222 | runtime torch.Size([158, 382]): 0:02:05.884663\n",
      "2024-10-22 10:06:47,015 - __main__ - INFO - written batch 223 | runtime torch.Size([162, 431]): 0:02:28.964140\n",
      "2024-10-22 10:08:43,700 - __main__ - INFO - written batch 224 | runtime torch.Size([164, 348]): 0:01:56.684148\n",
      "2024-10-22 10:10:52,195 - __main__ - INFO - written batch 225 | runtime torch.Size([157, 391]): 0:02:08.494026\n",
      "2024-10-22 10:14:11,888 - __main__ - INFO - written batch 226 | runtime torch.Size([178, 512]): 0:03:19.692117\n",
      "2024-10-22 10:15:51,301 - __main__ - INFO - written batch 227 | runtime torch.Size([130, 367]): 0:01:39.412106\n",
      "2024-10-22 10:15:51,303 - __main__ - INFO - overall runtime: 10:28:17.784046 | OBI description MULTILINGUAL_E5_LARGE_INSTRUCT\n",
      "2024-10-22 10:15:51,304 - __main__ - INFO - ebedding: BAAI/bge-m3\n"
     ]
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a09fd89009454776a62da92ee1d93a73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6bf1d1da9ced4665a6da6c5e06514633"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b054396ba3754768af7852cec2656f12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff22d2c7368a4f19932384df33bba743"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "581b77304b4c4aee9ae21c8ed5e01602"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42dbfbe55e574b0eb6078f1f7b8dcd0f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/23/2c/232ca60237b0bb19bb6c28c5a6c8af79f2e423333a9626aad445543b80fbf31e/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1729839616&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTgzOTYxNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzIzLzJjLzIzMmNhNjAyMzdiMGJiMTliYjZjMjhjNWE2YzhhZjc5ZjJlNDIzMzMzYTk2MjZhYWQ0NDU1NDNiODBmYmYzMWUvYjVlMGNlMzQ3MGFiZjVlZjM4MzFhYTFiZDU1NTNiNDg2ODAzZTgzMjUxNTkwYWI3ZmYzNWExMTdjZjZhYWQzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JMtGu8W-TrEGlgsxoTOx2cI6LG-yVX3zoO6ecpkDSALOxAW4Cd-asYc-HY666J-eizsT9H9d%7E3Gr6s%7EDKWfXsTUgWRRlY1fjgk19bIGEmJ-cETLKBQLYIKc1xsihKpZjY5ZeadaseCxFmV4pZ4jPbPw0ZRTEmSlolGzjZcOxTnBQYa-MoYfLiLIOVx%7EyPnd1N2FBZHfinyBcMTz7lQ%7EuUUHPWBXym9m8ChOhVoiw6ZIEg%7E4PpzBjltmoaCejD0g33LNE1JOOMUS4daIqTZcE4UqEzw42zwYmCmLCrPCxB7kxMFSZ7gonDwVa8Llqnl5lzgkLtEJifKH9kRt7KiDShQ__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "2024-10-22 10:19:37,692 - huggingface_hub.file_download - WARNING - Error while downloading from https://cdn-lfs-us-1.hf.co/repos/23/2c/232ca60237b0bb19bb6c28c5a6c8af79f2e423333a9626aad445543b80fbf31e/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1729839616&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTgzOTYxNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzIzLzJjLzIzMmNhNjAyMzdiMGJiMTliYjZjMjhjNWE2YzhhZjc5ZjJlNDIzMzMzYTk2MjZhYWQ0NDU1NDNiODBmYmYzMWUvYjVlMGNlMzQ3MGFiZjVlZjM4MzFhYTFiZDU1NTNiNDg2ODAzZTgzMjUxNTkwYWI3ZmYzNWExMTdjZjZhYWQzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JMtGu8W-TrEGlgsxoTOx2cI6LG-yVX3zoO6ecpkDSALOxAW4Cd-asYc-HY666J-eizsT9H9d%7E3Gr6s%7EDKWfXsTUgWRRlY1fjgk19bIGEmJ-cETLKBQLYIKc1xsihKpZjY5ZeadaseCxFmV4pZ4jPbPw0ZRTEmSlolGzjZcOxTnBQYa-MoYfLiLIOVx%7EyPnd1N2FBZHfinyBcMTz7lQ%7EuUUHPWBXym9m8ChOhVoiw6ZIEg%7E4PpzBjltmoaCejD0g33LNE1JOOMUS4daIqTZcE4UqEzw42zwYmCmLCrPCxB7kxMFSZ7gonDwVa8Llqnl5lzgkLtEJifKH9kRt7KiDShQ__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:  72%|#######1  | 1.63G/2.27G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f854d012d984c659408ebae2d044119"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/23/2c/232ca60237b0bb19bb6c28c5a6c8af79f2e423333a9626aad445543b80fbf31e/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1729839616&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTgzOTYxNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzIzLzJjLzIzMmNhNjAyMzdiMGJiMTliYjZjMjhjNWE2YzhhZjc5ZjJlNDIzMzMzYTk2MjZhYWQ0NDU1NDNiODBmYmYzMWUvYjVlMGNlMzQ3MGFiZjVlZjM4MzFhYTFiZDU1NTNiNDg2ODAzZTgzMjUxNTkwYWI3ZmYzNWExMTdjZjZhYWQzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JMtGu8W-TrEGlgsxoTOx2cI6LG-yVX3zoO6ecpkDSALOxAW4Cd-asYc-HY666J-eizsT9H9d%7E3Gr6s%7EDKWfXsTUgWRRlY1fjgk19bIGEmJ-cETLKBQLYIKc1xsihKpZjY5ZeadaseCxFmV4pZ4jPbPw0ZRTEmSlolGzjZcOxTnBQYa-MoYfLiLIOVx%7EyPnd1N2FBZHfinyBcMTz7lQ%7EuUUHPWBXym9m8ChOhVoiw6ZIEg%7E4PpzBjltmoaCejD0g33LNE1JOOMUS4daIqTZcE4UqEzw42zwYmCmLCrPCxB7kxMFSZ7gonDwVa8Llqnl5lzgkLtEJifKH9kRt7KiDShQ__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "2024-10-22 10:19:58,670 - huggingface_hub.file_download - WARNING - Error while downloading from https://cdn-lfs-us-1.hf.co/repos/23/2c/232ca60237b0bb19bb6c28c5a6c8af79f2e423333a9626aad445543b80fbf31e/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1729839616&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTgzOTYxNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzIzLzJjLzIzMmNhNjAyMzdiMGJiMTliYjZjMjhjNWE2YzhhZjc5ZjJlNDIzMzMzYTk2MjZhYWQ0NDU1NDNiODBmYmYzMWUvYjVlMGNlMzQ3MGFiZjVlZjM4MzFhYTFiZDU1NTNiNDg2ODAzZTgzMjUxNTkwYWI3ZmYzNWExMTdjZjZhYWQzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JMtGu8W-TrEGlgsxoTOx2cI6LG-yVX3zoO6ecpkDSALOxAW4Cd-asYc-HY666J-eizsT9H9d%7E3Gr6s%7EDKWfXsTUgWRRlY1fjgk19bIGEmJ-cETLKBQLYIKc1xsihKpZjY5ZeadaseCxFmV4pZ4jPbPw0ZRTEmSlolGzjZcOxTnBQYa-MoYfLiLIOVx%7EyPnd1N2FBZHfinyBcMTz7lQ%7EuUUHPWBXym9m8ChOhVoiw6ZIEg%7E4PpzBjltmoaCejD0g33LNE1JOOMUS4daIqTZcE4UqEzw42zwYmCmLCrPCxB7kxMFSZ7gonDwVa8Llqnl5lzgkLtEJifKH9kRt7KiDShQ__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:  73%|#######3  | 1.67G/2.27G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc3c084d571b4bf0af0985142d07688f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/23/2c/232ca60237b0bb19bb6c28c5a6c8af79f2e423333a9626aad445543b80fbf31e/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1729839616&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTgzOTYxNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzIzLzJjLzIzMmNhNjAyMzdiMGJiMTliYjZjMjhjNWE2YzhhZjc5ZjJlNDIzMzMzYTk2MjZhYWQ0NDU1NDNiODBmYmYzMWUvYjVlMGNlMzQ3MGFiZjVlZjM4MzFhYTFiZDU1NTNiNDg2ODAzZTgzMjUxNTkwYWI3ZmYzNWExMTdjZjZhYWQzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JMtGu8W-TrEGlgsxoTOx2cI6LG-yVX3zoO6ecpkDSALOxAW4Cd-asYc-HY666J-eizsT9H9d%7E3Gr6s%7EDKWfXsTUgWRRlY1fjgk19bIGEmJ-cETLKBQLYIKc1xsihKpZjY5ZeadaseCxFmV4pZ4jPbPw0ZRTEmSlolGzjZcOxTnBQYa-MoYfLiLIOVx%7EyPnd1N2FBZHfinyBcMTz7lQ%7EuUUHPWBXym9m8ChOhVoiw6ZIEg%7E4PpzBjltmoaCejD0g33LNE1JOOMUS4daIqTZcE4UqEzw42zwYmCmLCrPCxB7kxMFSZ7gonDwVa8Llqnl5lzgkLtEJifKH9kRt7KiDShQ__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "2024-10-22 10:21:22,228 - huggingface_hub.file_download - WARNING - Error while downloading from https://cdn-lfs-us-1.hf.co/repos/23/2c/232ca60237b0bb19bb6c28c5a6c8af79f2e423333a9626aad445543b80fbf31e/b5e0ce3470abf5ef3831aa1bd5553b486803e83251590ab7ff35a117cf6aad38?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1729839616&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTgzOTYxNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzIzLzJjLzIzMmNhNjAyMzdiMGJiMTliYjZjMjhjNWE2YzhhZjc5ZjJlNDIzMzMzYTk2MjZhYWQ0NDU1NDNiODBmYmYzMWUvYjVlMGNlMzQ3MGFiZjVlZjM4MzFhYTFiZDU1NTNiNDg2ODAzZTgzMjUxNTkwYWI3ZmYzNWExMTdjZjZhYWQzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=JMtGu8W-TrEGlgsxoTOx2cI6LG-yVX3zoO6ecpkDSALOxAW4Cd-asYc-HY666J-eizsT9H9d%7E3Gr6s%7EDKWfXsTUgWRRlY1fjgk19bIGEmJ-cETLKBQLYIKc1xsihKpZjY5ZeadaseCxFmV4pZ4jPbPw0ZRTEmSlolGzjZcOxTnBQYa-MoYfLiLIOVx%7EyPnd1N2FBZHfinyBcMTz7lQ%7EuUUHPWBXym9m8ChOhVoiw6ZIEg%7E4PpzBjltmoaCejD0g33LNE1JOOMUS4daIqTZcE4UqEzw42zwYmCmLCrPCxB7kxMFSZ7gonDwVa8Llqnl5lzgkLtEJifKH9kRt7KiDShQ__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:  99%|#########8| 2.24G/2.27G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4cdc21940c94f95a514e688424cb75a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 10:21:27,597 - __main__ - INFO - store: STROYDVOR\n",
      "2024-10-22 10:21:28,151 - __main__ - INFO - field: title\n",
      "2024-10-22 10:21:37,961 - __main__ - INFO - written batch 0 | runtime torch.Size([200, 29]): 0:00:09.806912\n",
      "2024-10-22 10:21:50,335 - __main__ - INFO - written batch 1 | runtime torch.Size([200, 37]): 0:00:12.373159\n",
      "2024-10-22 10:22:04,698 - __main__ - INFO - written batch 2 | runtime torch.Size([200, 42]): 0:00:14.362170\n",
      "2024-10-22 10:22:18,238 - __main__ - INFO - written batch 3 | runtime torch.Size([200, 40]): 0:00:13.539601\n",
      "2024-10-22 10:22:27,934 - __main__ - INFO - written batch 4 | runtime torch.Size([200, 29]): 0:00:09.695031\n",
      "2024-10-22 10:22:38,818 - __main__ - INFO - written batch 5 | runtime torch.Size([200, 32]): 0:00:10.883639\n",
      "2024-10-22 10:22:48,939 - __main__ - INFO - written batch 6 | runtime torch.Size([200, 30]): 0:00:10.119202\n",
      "2024-10-22 10:22:58,797 - __main__ - INFO - written batch 7 | runtime torch.Size([200, 29]): 0:00:09.857441\n",
      "2024-10-22 10:23:10,026 - __main__ - INFO - written batch 8 | runtime torch.Size([200, 33]): 0:00:11.228858\n",
      "2024-10-22 10:23:23,574 - __main__ - INFO - written batch 9 | runtime torch.Size([200, 40]): 0:00:13.546790\n",
      "2024-10-22 10:23:32,896 - __main__ - INFO - written batch 10 | runtime torch.Size([200, 28]): 0:00:09.321380\n",
      "2024-10-22 10:23:46,077 - __main__ - INFO - written batch 11 | runtime torch.Size([200, 38]): 0:00:13.179994\n",
      "2024-10-22 10:23:57,272 - __main__ - INFO - written batch 12 | runtime torch.Size([200, 33]): 0:00:11.194376\n",
      "2024-10-22 10:24:08,573 - __main__ - INFO - written batch 13 | runtime torch.Size([200, 33]): 0:00:11.300467\n",
      "2024-10-22 10:24:20,456 - __main__ - INFO - written batch 14 | runtime torch.Size([200, 35]): 0:00:11.882100\n",
      "2024-10-22 10:24:29,418 - __main__ - INFO - written batch 15 | runtime torch.Size([200, 27]): 0:00:08.961334\n",
      "2024-10-22 10:24:41,036 - __main__ - INFO - written batch 16 | runtime torch.Size([200, 34]): 0:00:11.617226\n",
      "2024-10-22 10:24:51,139 - __main__ - INFO - written batch 17 | runtime torch.Size([200, 30]): 0:00:10.102969\n",
      "2024-10-22 10:25:00,390 - __main__ - INFO - written batch 18 | runtime torch.Size([200, 27]): 0:00:09.249652\n",
      "2024-10-22 10:25:10,652 - __main__ - INFO - written batch 19 | runtime torch.Size([200, 30]): 0:00:10.261185\n",
      "2024-10-22 10:25:21,881 - __main__ - INFO - written batch 20 | runtime torch.Size([200, 33]): 0:00:11.228710\n",
      "2024-10-22 10:25:32,558 - __main__ - INFO - written batch 21 | runtime torch.Size([200, 32]): 0:00:10.675939\n",
      "2024-10-22 10:25:40,440 - __main__ - INFO - written batch 22 | runtime torch.Size([200, 23]): 0:00:07.881253\n",
      "2024-10-22 10:25:48,280 - __main__ - INFO - written batch 23 | runtime torch.Size([200, 23]): 0:00:07.839472\n",
      "2024-10-22 10:25:56,280 - __main__ - INFO - written batch 24 | runtime torch.Size([200, 23]): 0:00:07.998239\n",
      "2024-10-22 10:26:05,553 - __main__ - INFO - written batch 25 | runtime torch.Size([200, 27]): 0:00:09.272495\n",
      "2024-10-22 10:26:15,880 - __main__ - INFO - written batch 26 | runtime torch.Size([200, 30]): 0:00:10.326817\n",
      "2024-10-22 10:26:26,130 - __main__ - INFO - written batch 27 | runtime torch.Size([200, 30]): 0:00:10.249552\n",
      "2024-10-22 10:26:34,012 - __main__ - INFO - written batch 28 | runtime torch.Size([200, 23]): 0:00:07.881028\n",
      "2024-10-22 10:26:43,220 - __main__ - INFO - written batch 29 | runtime torch.Size([200, 27]): 0:00:09.206891\n",
      "2024-10-22 10:26:54,068 - __main__ - INFO - written batch 30 | runtime torch.Size([200, 32]): 0:00:10.847232\n",
      "2024-10-22 10:27:03,516 - __main__ - INFO - written batch 31 | runtime torch.Size([200, 28]): 0:00:09.446827\n",
      "2024-10-22 10:27:12,989 - __main__ - INFO - written batch 32 | runtime torch.Size([200, 28]): 0:00:09.472483\n",
      "2024-10-22 10:27:23,860 - __main__ - INFO - written batch 33 | runtime torch.Size([200, 32]): 0:00:10.870094\n",
      "2024-10-22 10:27:34,073 - __main__ - INFO - written batch 34 | runtime torch.Size([200, 30]): 0:00:10.213007\n",
      "2024-10-22 10:27:43,580 - __main__ - INFO - written batch 35 | runtime torch.Size([200, 28]): 0:00:09.505549\n",
      "2024-10-22 10:27:53,565 - __main__ - INFO - written batch 36 | runtime torch.Size([200, 29]): 0:00:09.984166\n",
      "2024-10-22 10:28:05,647 - __main__ - INFO - written batch 37 | runtime torch.Size([200, 36]): 0:00:12.081342\n",
      "2024-10-22 10:28:18,350 - __main__ - INFO - written batch 38 | runtime torch.Size([200, 38]): 0:00:12.702256\n",
      "2024-10-22 10:28:26,469 - __main__ - INFO - written batch 39 | runtime torch.Size([200, 25]): 0:00:08.118192\n",
      "2024-10-22 10:28:41,727 - __main__ - INFO - written batch 40 | runtime torch.Size([200, 44]): 0:00:15.257664\n",
      "2024-10-22 10:28:57,564 - __main__ - INFO - written batch 41 | runtime torch.Size([200, 45]): 0:00:15.836035\n",
      "2024-10-22 10:29:06,660 - __main__ - INFO - written batch 42 | runtime torch.Size([200, 27]): 0:00:09.094981\n",
      "2024-10-22 10:29:16,892 - __main__ - INFO - written batch 43 | runtime torch.Size([200, 30]): 0:00:10.231186\n",
      "2024-10-22 10:29:28,481 - __main__ - INFO - written batch 44 | runtime torch.Size([200, 34]): 0:00:11.589110\n",
      "2024-10-22 10:29:39,152 - __main__ - INFO - written batch 45 | runtime torch.Size([200, 32]): 0:00:10.669565\n",
      "2024-10-22 10:29:54,235 - __main__ - INFO - written batch 46 | runtime torch.Size([200, 44]): 0:00:15.082586\n",
      "2024-10-22 10:30:06,126 - __main__ - INFO - written batch 47 | runtime torch.Size([200, 35]): 0:00:11.890005\n",
      "2024-10-22 10:30:15,665 - __main__ - INFO - written batch 48 | runtime torch.Size([200, 29]): 0:00:09.537799\n",
      "2024-10-22 10:30:27,244 - __main__ - INFO - written batch 49 | runtime torch.Size([200, 34]): 0:00:11.578504\n",
      "2024-10-22 10:30:42,100 - __main__ - INFO - written batch 50 | runtime torch.Size([200, 43]): 0:00:14.855051\n",
      "2024-10-22 10:30:53,663 - __main__ - INFO - written batch 51 | runtime torch.Size([200, 34]): 0:00:11.562140\n",
      "2024-10-22 10:31:04,171 - __main__ - INFO - written batch 52 | runtime torch.Size([200, 31]): 0:00:10.507709\n",
      "2024-10-22 10:31:13,548 - __main__ - INFO - written batch 53 | runtime torch.Size([200, 28]): 0:00:09.376236\n",
      "2024-10-22 10:31:23,478 - __main__ - INFO - written batch 54 | runtime torch.Size([200, 30]): 0:00:09.929363\n",
      "2024-10-22 10:31:33,983 - __main__ - INFO - written batch 55 | runtime torch.Size([200, 31]): 0:00:10.504109\n",
      "2024-10-22 10:31:45,234 - __main__ - INFO - written batch 56 | runtime torch.Size([200, 33]): 0:00:11.249891\n",
      "2024-10-22 10:31:59,399 - __main__ - INFO - written batch 57 | runtime torch.Size([200, 42]): 0:00:14.164527\n",
      "2024-10-22 10:32:10,682 - __main__ - INFO - written batch 58 | runtime torch.Size([200, 33]): 0:00:11.281700\n",
      "2024-10-22 10:32:21,411 - __main__ - INFO - written batch 59 | runtime torch.Size([200, 32]): 0:00:10.728308\n",
      "2024-10-22 10:32:31,975 - __main__ - INFO - written batch 60 | runtime torch.Size([200, 31]): 0:00:10.563072\n",
      "2024-10-22 10:32:48,201 - __main__ - INFO - written batch 61 | runtime torch.Size([200, 48]): 0:00:16.225986\n",
      "2024-10-22 10:33:03,735 - __main__ - INFO - written batch 62 | runtime torch.Size([200, 45]): 0:00:15.533283\n",
      "2024-10-22 10:33:15,654 - __main__ - INFO - written batch 63 | runtime torch.Size([200, 35]): 0:00:11.918658\n",
      "2024-10-22 10:33:28,498 - __main__ - INFO - written batch 64 | runtime torch.Size([200, 38]): 0:00:12.843288\n",
      "2024-10-22 10:33:42,655 - __main__ - INFO - written batch 65 | runtime torch.Size([200, 42]): 0:00:14.155394\n",
      "2024-10-22 10:33:53,891 - __main__ - INFO - written batch 66 | runtime torch.Size([200, 33]): 0:00:11.235229\n",
      "2024-10-22 10:34:01,836 - __main__ - INFO - written batch 67 | runtime torch.Size([200, 24]): 0:00:07.944443\n",
      "2024-10-22 10:34:10,559 - __main__ - INFO - written batch 68 | runtime torch.Size([200, 26]): 0:00:08.721693\n",
      "2024-10-22 10:34:21,843 - __main__ - INFO - written batch 69 | runtime torch.Size([200, 33]): 0:00:11.283375\n",
      "2024-10-22 10:34:26,120 - __main__ - INFO - written batch 70 | runtime torch.Size([103, 26]): 0:00:04.275898\n",
      "2024-10-22 10:34:26,121 - __main__ - INFO - overall runtime: 0:12:57.969329 | STROYDVOR title BGE_M3\n",
      "2024-10-22 10:34:26,122 - __main__ - INFO - field: description\n",
      "2024-10-22 10:39:52,281 - __main__ - INFO - written batch 0 | runtime torch.Size([179, 728]): 0:05:26.158499\n",
      "2024-10-22 10:42:43,880 - __main__ - INFO - written batch 1 | runtime torch.Size([194, 412]): 0:02:51.596400\n",
      "2024-10-22 10:47:23,816 - __main__ - INFO - written batch 2 | runtime torch.Size([178, 649]): 0:04:39.935118\n",
      "2024-10-22 10:51:04,127 - __main__ - INFO - written batch 3 | runtime torch.Size([198, 500]): 0:03:40.310238\n",
      "2024-10-22 10:54:59,756 - __main__ - INFO - written batch 4 | runtime torch.Size([199, 524]): 0:03:55.628993\n",
      "2024-10-22 10:58:09,219 - __main__ - INFO - written batch 5 | runtime torch.Size([192, 456]): 0:03:09.461919\n",
      "2024-10-22 11:45:18,796 - __main__ - INFO - written batch 6 | runtime torch.Size([131, 1318]): 0:47:09.573382\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from create_embeddings.schemas.embedding import ProductEmbedding\n",
    "from parsers.runnures.utils.csv import CsvWriter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "for embedding in ebeddins_list:\n",
    "    if start_from_model == embedding.name:\n",
    "        start_from_model = None\n",
    "    if start_from_model is not None:\n",
    "        continue\n",
    "    logger.info(f'ebedding: {embedding.name}')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(embedding.name)\n",
    "    model = AutoModel.from_pretrained(embedding.name)\n",
    "    for store, csv_path in store_map.items():\n",
    "        if start_from_store == store:\n",
    "            start_from_store = None\n",
    "        if start_from_store is not None:\n",
    "            continue\n",
    "        logger.info(f'store: {store}')\n",
    "        df = pd.read_csv(csv_path)\n",
    "        for field in fields_to_encode:\n",
    "            if start_from_field == field:\n",
    "                start_from_field = None\n",
    "            if start_from_field is not None:\n",
    "                continue\n",
    "            logger.info(f'field: {field}')\n",
    "            datetime_start_over_all = datetime.datetime.now()\n",
    "            csv_writer: CsvWriter[ProductEmbedding] = CsvWriter(f'products_embeddings_{store}_{field}_{embedding.name.name}.csv', ProductEmbedding, path=r'./data/')\n",
    "            i = 0\n",
    "            while True:\n",
    "                datetime_start = datetime.datetime.now()\n",
    "                batch_df = df[[uid_column, field]][BATCH_SIZE * i:BATCH_SIZE * (i+1)]\n",
    "                if len(batch_df) == 0:\n",
    "                    break\n",
    "                batch_df.dropna(inplace=True)\n",
    "                uid_data = batch_df[uid_column].tolist()\n",
    "                data = batch_df[field].tolist()\n",
    "\n",
    "                encoded_input = tokenizer(data, padding=True, truncation=True, return_tensors='pt')\n",
    "                with torch.no_grad():\n",
    "                    model_output = model(**encoded_input)\n",
    "                    sentence_embeddings = model_output[0][:, 0]\n",
    "\n",
    "                sentence_embeddings_list = sentence_embeddings.tolist()\n",
    "                csv_data_to_write = []\n",
    "                for write_index in range(len(uid_data)):\n",
    "                    csv_data_to_write.append(ProductEmbedding(\n",
    "                            uid=uid_data[write_index],\n",
    "                            field=field,\n",
    "                            store=store,\n",
    "                            model=embedding.name,\n",
    "                            embedding=sentence_embeddings_list[write_index]\n",
    "                    ))\n",
    "                csv_writer.write_lines(csv_data_to_write)\n",
    "                logger.info(f'written batch {i} | runtime {encoded_input[\"input_ids\"].size()}: {datetime.datetime.now() - datetime_start}')\n",
    "\n",
    "                i += 1\n",
    "            del csv_writer\n",
    "            logger.info(f'overall runtime: {datetime.datetime.now() - datetime_start_over_all} | {store} {field} {embedding.name.name}')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-10-21T20:47:28.490244209Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# R&D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_870/2444982175.py:2: DtypeWarning: Columns (35,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_b = pd.read_csv('/home/roman/PycharmProjects/personal/diploma/parsers/runnures/obi/data/products_merged.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_a = pd.read_csv('/home/roman/PycharmProjects/personal/diploma/parsers/runnures/stroydvor/data/products.csv')\n",
    "df_b = pd.read_csv('/home/roman/PycharmProjects/personal/diploma/parsers/runnures/obi/data/products_merged.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-20T17:25:45.511143723Z",
     "start_time": "2024-10-20T17:25:43.054318854Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14103 entries, 0 to 14102\n",
      "Data columns (total 50 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   uid                                       14103 non-null  object \n",
      " 1   store                                     14103 non-null  object \n",
      " 2   title                                     14103 non-null  object \n",
      " 3   url                                       14103 non-null  object \n",
      " 4   category                                  14103 non-null  object \n",
      " 5   description                               8916 non-null   object \n",
      " 6   images                                    14103 non-null  object \n",
      " 7   images__0                                 14095 non-null  object \n",
      " 8   images__1                                 8349 non-null   object \n",
      " 9   images__2                                 5485 non-null   object \n",
      " 10  images__3                                 3233 non-null   object \n",
      " 11  images__4                                 1733 non-null   object \n",
      " 12  images__5                                 972 non-null    object \n",
      " 13  price                                     14103 non-null  float64\n",
      " 14  properties__as_text                       14088 non-null  object \n",
      " 15  properties__as_dict                       14088 non-null  object \n",
      " 16  properties__brand                         11887 non-null  object \n",
      " 17  properties__label                         6785 non-null   object \n",
      " 18  properties__country                       8154 non-null   object \n",
      " 19  properties__color                         5815 non-null   object \n",
      " 20  properties__material                      7334 non-null   object \n",
      " 21  properties__mass__raw                     5073 non-null   object \n",
      " 22  properties__mass__num                     5073 non-null   float64\n",
      " 23  properties__mass__unit                    4839 non-null   object \n",
      " 24  properties__volume__raw                   867 non-null    object \n",
      " 25  properties__volume__num                   867 non-null    float64\n",
      " 26  properties__volume__unit                  866 non-null    object \n",
      " 27  properties__dimensions__raw               7261 non-null   object \n",
      " 28  properties__dimensions__d_list            14103 non-null  object \n",
      " 29  properties__dimensions__d_list__0         7261 non-null   float64\n",
      " 30  properties__dimensions__d_list__1         3289 non-null   float64\n",
      " 31  properties__dimensions__d_list__2         1578 non-null   float64\n",
      " 32  properties__dimensions__d_list__3         163 non-null    float64\n",
      " 33  properties__dimensions__d_list__4         0 non-null      float64\n",
      " 34  properties__dimensions__d_list__5         0 non-null      float64\n",
      " 35  properties__dimensions__all_units_parsed  7261 non-null   object \n",
      " 36  properties__art_codes                     14103 non-null  object \n",
      " 37  properties__art_codes__0                  14103 non-null  int64  \n",
      " 38  properties__art_codes__1                  4963 non-null   object \n",
      " 39  properties__art_codes__2                  582 non-null    object \n",
      " 40  properties__art_codes__3                  0 non-null      float64\n",
      " 41  properties__art_codes__4                  0 non-null      float64\n",
      " 42  properties__art_codes__5                  0 non-null      float64\n",
      " 43  properties__category_list_raw             14103 non-null  object \n",
      " 44  properties__category_list_raw__0          14103 non-null  object \n",
      " 45  properties__category_list_raw__1          14103 non-null  object \n",
      " 46  properties__category_list_raw__2          12215 non-null  object \n",
      " 47  properties__category_list_raw__3          2907 non-null   object \n",
      " 48  properties__category_list_raw__4          194 non-null    object \n",
      " 49  properties__category_list_raw__5          0 non-null      float64\n",
      "dtypes: float64(13), int64(1), object(36)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_a.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-20T17:25:59.072625380Z",
     "start_time": "2024-10-20T17:25:58.963363820Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45571 entries, 0 to 45570\n",
      "Data columns (total 50 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   uid                                       45571 non-null  object \n",
      " 1   store                                     45571 non-null  object \n",
      " 2   title                                     45571 non-null  object \n",
      " 3   url                                       45571 non-null  object \n",
      " 4   category                                  45571 non-null  object \n",
      " 5   description                               39457 non-null  object \n",
      " 6   images                                    45571 non-null  object \n",
      " 7   images__0                                 45571 non-null  object \n",
      " 8   images__1                                 21810 non-null  object \n",
      " 9   images__2                                 14436 non-null  object \n",
      " 10  images__3                                 9325 non-null   object \n",
      " 11  images__4                                 6329 non-null   object \n",
      " 12  images__5                                 4295 non-null   object \n",
      " 13  price                                     45571 non-null  float64\n",
      " 14  properties__as_text                       45571 non-null  object \n",
      " 15  properties__as_dict                       45571 non-null  object \n",
      " 16  properties__brand                         45571 non-null  object \n",
      " 17  properties__label                         45571 non-null  object \n",
      " 18  properties__country                       0 non-null      float64\n",
      " 19  properties__color                         45384 non-null  object \n",
      " 20  properties__material                      18301 non-null  object \n",
      " 21  properties__mass__raw                     45548 non-null  object \n",
      " 22  properties__mass__num                     45548 non-null  float64\n",
      " 23  properties__mass__unit                    20692 non-null  object \n",
      " 24  properties__volume__raw                   3637 non-null   object \n",
      " 25  properties__volume__num                   3637 non-null   float64\n",
      " 26  properties__volume__unit                  3631 non-null   object \n",
      " 27  properties__dimensions__raw               45570 non-null  object \n",
      " 28  properties__dimensions__d_list            45571 non-null  object \n",
      " 29  properties__dimensions__d_list__0         45547 non-null  float64\n",
      " 30  properties__dimensions__d_list__1         45537 non-null  float64\n",
      " 31  properties__dimensions__d_list__2         45529 non-null  float64\n",
      " 32  properties__dimensions__d_list__3         0 non-null      float64\n",
      " 33  properties__dimensions__d_list__4         0 non-null      float64\n",
      " 34  properties__dimensions__d_list__5         0 non-null      float64\n",
      " 35  properties__dimensions__all_units_parsed  45570 non-null  object \n",
      " 36  properties__art_codes                     45571 non-null  object \n",
      " 37  properties__art_codes__0                  45571 non-null  int64  \n",
      " 38  properties__art_codes__1                  1343 non-null   object \n",
      " 39  properties__art_codes__2                  0 non-null      float64\n",
      " 40  properties__art_codes__3                  0 non-null      float64\n",
      " 41  properties__art_codes__4                  0 non-null      float64\n",
      " 42  properties__art_codes__5                  0 non-null      float64\n",
      " 43  properties__category_list_raw             45571 non-null  object \n",
      " 44  properties__category_list_raw__0          45571 non-null  object \n",
      " 45  properties__category_list_raw__1          45571 non-null  object \n",
      " 46  properties__category_list_raw__2          45106 non-null  object \n",
      " 47  properties__category_list_raw__3          4858 non-null   object \n",
      " 48  properties__category_list_raw__4          442 non-null    object \n",
      " 49  properties__category_list_raw__5          5 non-null      object \n",
      "dtypes: float64(14), int64(1), object(35)\n",
      "memory usage: 17.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_b.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-20T17:26:04.379084332Z",
     "start_time": "2024-10-20T17:26:04.313802623Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raise Exception"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "sentence_test = df_a.iloc[5000:6000]\n",
    "sentence_test_title = list(sentence_test['title'])\n",
    "sentence_test_desc = list(filter(lambda x: not pd.isna(x), sentence_test['description']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-20T17:33:01.433159377Z",
     "start_time": "2024-10-20T17:33:01.426295423Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use:  sergeyzh/rubert-tiny-turbo\n",
      "title\n",
      "token_size torch.Size([1000, 29])\n",
      "runtime 1000: 0:00:00.665106\n",
      "\n",
      "description\n",
      "token_size torch.Size([547, 425])\n",
      "runtime 547: 0:00:06.257252\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import datetime\n",
    "\n",
    "current_embedding = ebeddins_list[0]\n",
    "print(\"Use: \", current_embedding.name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(current_embedding.name)\n",
    "model = AutoModel.from_pretrained(current_embedding.name)\n",
    "\n",
    "print('title')\n",
    "encoded_input = tokenizer(sentence_test_title, padding=True, truncation=True, return_tensors='pt')\n",
    "print('token_size', encoded_input['input_ids'].size())\n",
    "\n",
    "datetime_start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "    sentence_embeddings = model_output[0][:, 0]\n",
    "datetime_end = datetime.datetime.now()\n",
    "print(f'runtime {len(sentence_test_title)}: {datetime_end - datetime_start}')\n",
    "\n",
    "\n",
    "print('\\ndescription')\n",
    "encoded_input = tokenizer(sentence_test_desc, padding=True, truncation=True, return_tensors='pt')\n",
    "print('token_size', encoded_input['input_ids'].size())\n",
    "\n",
    "datetime_start = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "    sentence_embeddings = model_output[0][:, 0]\n",
    "datetime_end = datetime.datetime.now()\n",
    "print(f'runtime {len(sentence_test_desc)}: {datetime_end - datetime_start}')\n",
    "\n",
    "# sentence_embeddings_norm = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-20T19:30:16.222621635Z",
     "start_time": "2024-10-20T19:30:08.209629701Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "single_encoded_input = tokenizer(sentence_test_title[0], padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    single_model_output = model(**encoded_input)\n",
    "    single_sentence_embeddings = model_output[0][:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-20T19:02:51.237235676Z",
     "start_time": "2024-10-20T19:02:44.819432158Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(all(sentence_embeddings[0] == single_sentence_embeddings[0]))\n",
    "sentence_embeddings_norm = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "single_sentence_embeddings_norm = torch.nn.functional.normalize(single_sentence_embeddings, p=2, dim=1)\n",
    "print(all(sentence_embeddings_norm[0] == single_sentence_embeddings_norm[0]))\n",
    "print(all(sentence_embeddings_norm[0] == sentence_embeddings[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-20T19:07:33.236135322Z",
     "start_time": "2024-10-20T19:07:33.191770283Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.1968,  0.0805, -0.0681,  ...,  0.6348, -0.2396, -0.0982],\n        [ 0.2096, -0.0101, -0.0631,  ...,  0.6291, -0.2470, -0.0917],\n        [ 0.1825,  0.1019, -0.0212,  ...,  0.6207, -0.2527, -0.0990],\n        ...,\n        [ 0.3311,  0.2308, -0.0581,  ...,  0.6759,  0.0426, -0.1563],\n        [ 0.2736,  0.2664, -0.0208,  ...,  0.6345,  0.0157, -0.0923],\n        [ 0.3377,  0.2336, -0.0278,  ...,  0.6733,  0.0401, -0.1745]])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-20T19:15:14.704083969Z",
     "start_time": "2024-10-20T19:15:14.700502916Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "sentence_embeddings_list = sentence_embeddings.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-20T19:16:39.126355800Z",
     "start_time": "2024-10-20T19:16:39.050022502Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "312"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_embeddings_list[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-20T19:16:53.973752394Z",
     "start_time": "2024-10-20T19:16:53.971377574Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
